## Model-Market – Model Comparison (A)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| AI Benchmark              | Benchmarking and comparison of AI models on mobile/edge devices.              | [Website](https://ai-benchmark.com) |
| AllenNLP Model Comparison | Tools for comparing NLP models built with AllenNLP.                          | [GitHub](https://github.com/allenai/allennlp) |
| AutoML Benchmark          | Comparative benchmarks of AutoML frameworks.                                 | [GitHub](https://github.com/openml/automlbenchmark) |
| Awesome ML Benchmarks     | Curated collection of ML/DL model benchmarking and comparison resources.      | [GitHub](https://github.com/lyakaap/awesome-ml-benchmarks) |
| AWS Model Benchmarking    | Amazon Web Services tools for model performance and scalability comparison.   | [AWS Docs](https://aws.amazon.com/machine-learning/) |

## Model-Market – Model Comparison (B)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| BigML Benchmark           | Benchmarking machine learning models on BigML platform.                        | [Website](https://www.bigml.com) |
| BrainBench Models         | Tools and datasets for comparing neural network performance.                   | [Website](https://www.brainbench.com) |
| BertScore Comparison      | Evaluation and comparison of NLP models using BERTScore metric.               | [GitHub](https://github.com/Tiiiger/bert_score) |
| BenchmarkML               | General-purpose ML model comparison platform.                                  | [GitHub](https://github.com/BenchmarkML/benchmarkml) |
| BLINK Benchmark           | Comparison of entity linking and NLP models.                                   | [GitHub](https://github.com/facebookresearch/BLINK) |

## Model-Market – Model Comparison (C)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| CVPR Model Zoo            | Collection of computer vision models for benchmarking.                        | [Website](https://cvpr2023.thecvf.com) |
| CheckList                 | Benchmarking NLP models using behavioral testing.                              | [GitHub](https://github.com/marcotcr/checklist) |
| COCO Detection Benchmark  | Comparison of object detection models on COCO dataset.                        | [Website](https://cocodataset.org) |
| Caffe Model Zoo           | Pretrained deep learning models and benchmarks in Caffe framework.            | [GitHub](https://github.com/BVLC/caffe/wiki/Model-Zoo) |
| Cloud ML Benchmarks       | Performance comparison of ML models on cloud platforms.                       | [Website](https://cloud.google.com/ai-platform) |

## Model-Market – Model Comparison (D)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| DeepBench                | Benchmarking deep learning operations on different hardware.                   | [GitHub](https://github.com/baidu-research/DeepBench) |
| DeepSpeed Benchmark      | Performance comparison of large-scale models using DeepSpeed.                  | [GitHub](https://github.com/microsoft/DeepSpeed) |
| DistilBERT Benchmarks    | Comparisons of smaller, faster Transformer models vs. BERT.                    | [GitHub](https://github.com/huggingface/transformers) |
| DLPerf                   | NVIDIA’s deep learning performance benchmarking suite.                         | [GitHub](https://github.com/NVIDIA/DeepLearningExamples/tree/master/DLPerf) |
| DAWNBench                | End-to-end deep learning training time benchmarks.                             | [Website](https://dawn.cs.stanford.edu/benchmark/) |

## Model-Market – Model Comparison (E)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| EfficientNet Benchmarks  | Comparisons of EfficientNet vs. other CNN architectures.                       | [GitHub](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet) |
| EvalAI                   | Platform for evaluating and comparing ML/DL models across challenges.          | [GitHub](https://github.com/Cloud-CV/EvalAI) |
| ELMo Benchmarks          | Comparison of ELMo embeddings vs. other NLP models.                            | [GitHub](https://github.com/allenai/allennlp) |
| EdgeBench                | Benchmarks for ML model performance on edge and mobile devices.                | [GitHub](https://github.com/mlcommons/mobile) |

## Model-Market – Model Comparison (F)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| Fairseq Benchmarks        | Comparisons of Fairseq NLP models (BART, RoBERTa, etc.) across tasks.          | [GitHub](https://github.com/facebookresearch/fairseq) |
| FastText Benchmarks       | Evaluation of FastText vs. Word2Vec, GloVe, and other embeddings.              | [GitHub](https://github.com/facebookresearch/fastText) |
| Flair NLP Comparisons     | Benchmarks of Flair embeddings against BERT, ELMo, and others.                 | [GitHub](https://github.com/flairNLP/flair) |
| Focal Loss Benchmarks     | Comparing performance of models using Focal Loss vs. standard cross-entropy.   | [GitHub](https://github.com/facebookresearch/fvcore) |

## Model-Market – Model Comparison (G)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| GPT Model Comparisons      | Benchmarks of GPT-2, GPT-3, GPT-4, and other OpenAI models across tasks.     | [GitHub](https://github.com/openai/gpt-3) |
| GNN Benchmarking           | Comparison of Graph Neural Networks (GCN, GAT, GraphSAGE) on standard datasets. | [GitHub](https://github.com/pyg-team/pytorch_geometric) |
| Google ML Model Zoo        | Google’s pre-trained models compared on vision, NLP, and speech tasks.        | [GitHub](https://github.com/tensorflow/models) |
| Gradient Boosting Comparisons | Performance benchmarks of XGBoost, LightGBM, CatBoost on tabular data.      | [GitHub](https://github.com/dmlc/xgboost) |

## Model-Market – Model Comparison (H)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| Hugging Face Model Hub     | Comparison of transformer models (BERT, GPT, T5, etc.) for NLP tasks.       | [GitHub](https://github.com/huggingface/transformers) |
| H2O.ai Model Benchmark     | Benchmarks for H2O’s ML models including GBM, XGBoost, and Deep Learning.  | [GitHub](https://github.com/h2oai/h2o-3) |
| Hyperparameter Tuning Comparisons | Evaluating tuning strategies for ML/DL models (Optuna, Ray Tune, Hyperopt). | [GitHub](https://github.com/optuna/optuna) |
| HuggingFace Datasets       | Benchmarking models on standard NLP datasets.                                 | [GitHub](https://github.com/huggingface/datasets) |

## Model-Market – Model Comparison (I)

| **Name**                  | **Known For**                                                                 | **Link** |
|---------------------------|-------------------------------------------------------------------------------|----------|
| Imagenet Model Zoo         | Comparison of pre-trained models on ImageNet for image classification.      | [GitHub](https://github.com/anishathalye/imagenet-model-zoo) |
| InsightFace Benchmarks     | Evaluation of face recognition models on standard datasets.                 | [GitHub](https://github.com/deepinsight/insightface) |
| iMaterialist Fashion Benchmarks | Model comparisons on fashion and product recognition datasets.             | [GitHub](https://github.com/visipedia/imat) |
| Intel OpenVINO Model Zoo   | Benchmarking models optimized for Intel hardware.                            | [GitHub](https://github.com/openvinotoolkit/open_model_zoo) |

